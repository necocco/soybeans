import streamlit as st
from PIL import Image
import torch
import torchvision.transforms as transforms
from model import Net
import time
from PIL import Image, ExifTags
import base64
import pygame
import random
import os
from PIL import Image
from torchvision import transforms
from glob import glob
from natsort import natsorted
from torchvision.models import resnet34
from torchmetrics.functional import accuracy
import torch
import streamlit as st
import pandas as pd
import plotly.graph_objects as govenv
import plotly.express as px

# ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
# ã“ã“ã§ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å®šç¾©ã—ã¦ã€é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
# ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã®å®šç¾©ï¼ˆçµµæ–‡å­—ã‚‚å«ã‚€ï¼‰
labels = {
    0: "Really?ã€€Soybeans?? ğŸ‘»ã€€ãªã‚“ã ã‚­ãƒŸã¯ï¼Ÿ",
    1: "ã‚ã‚‹ã„å­ã€€ğŸ˜­",
    2: "ã„ã„å­ã€€ğŸ˜",
    3: "ãµã¤ã†ã®å­ã€€ğŸ˜‘"
}


# Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®šç¾©
# CSSã‚’ä½¿ã£ã¦èƒŒæ™¯è‰²ã‚’è¨­å®šã™ã‚‹é–¢æ•°
def set_bg_color():
    st.markdown(
        f"""
        <style>
        .stApp {{
            background-color:#FFFFCC;
        }}
        </style>
        """,
        unsafe_allow_html=True
    )

# é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦èƒŒæ™¯è‰²ã‚’è¨­å®š
set_bg_color()

import streamlit as st

st.sidebar.write(':blue[**å¤§è±†é¸åˆ¥ã®ãŸã‚ã®ç”»åƒåˆ¤åˆ¥ã‚¢ãƒ—ãƒª**]')
st.sidebar.write("äºˆæ¸¬çµæœã¯ä»¥ä¸‹ã®ï¼”ã¤ã«åˆ†ã‘ã‚‰ã‚Œã¾ã™")
st.sidebar.write("**ãƒ»ã„ã„å­**ï¼šè‰¯è³ªãªå¤§è±†")
st.sidebar.write("**ãƒ»ãµã¤ã†ã®å­**ï¼šå‘³å™Œç­‰ã®åŠ å·¥ç”¨ã«ä½¿ãˆã‚‹å¤§è±†")
st.sidebar.write("**ãƒ»ã‚ã‚‹ã„å­**ï¼šå“è³ªãŒæ‚ªã„å¤§è±†ã€‚é³¥ã«ã‚ã’ã¾ã—ã‚‡ã†")
st.sidebar.write("**ãƒ»Really?ã€€Soybeans??**ï¼šã‚ãªãŸã¯ã ãã‚Œï¼Ÿ")

# ç”»åƒã®èª­ã¿è¾¼ã¿
img = Image.open("./IMG_9183-1.JPG")

# Exifæƒ…å ±ã‚’å–å¾—ã—ã€å‘ãæƒ…å ±ã‚’ç¢ºèªã™ã‚‹
try:
    for orientation in ExifTags.TAGS.keys():
        if ExifTags.TAGS[orientation] == 'Orientation':
            exif = dict(img._getexif().items())

            if exif[orientation] == 3:
                img = img.rotate(180, expand=True)
            elif exif[orientation] == 6:
                img = img.rotate(270, expand=True)
            elif exif[orientation] == 8:
                img = img.rotate(90, expand=True)
except (AttributeError, KeyError, IndexError):
    # Exifæƒ…å ±ãŒãªã„å ´åˆã‚„ã€å‘ãæƒ…å ±ãŒå–å¾—ã§ããªã„å ´åˆã¯ä½•ã‚‚ã—ãªã„
    pass

# ç”»åƒã‚’è¡¨ç¤ºã™ã‚‹
st.sidebar.image(img, use_column_width=True)

def main():
    # Pygameã®åˆæœŸåŒ–
    pygame.init()
    pygame.mixer.init()


    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿½åŠ 
    st.markdown("<div class='content-container'>", unsafe_allow_html=True)
    st.subheader('å¤§è±†ç”»åƒåˆ¤å®šï½ ã‚ˆã„å­ãƒ»ã‚ã‚‹ã„å­ãƒ»ãµã¤ã†ã®å­ ', divider='rainbow')
    st.title('_:red[Soybeans checker] app_ :mag:')
    st.markdown("</div>", unsafe_allow_html=True)

    

    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    image_directory = "./images/input/test"

    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è¦§ã‚’å–å¾—
    image_files = os.listdir(image_directory)

    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è¦§ã‚’è¡¨ç¤ºã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚ˆã†ã«æŒ‡ç¤º
    selected_image_file = st.selectbox("â‘ ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„:", image_files)

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠã—ãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
    image_path = os.path.join(image_directory, selected_image_file)

    # é¸æŠã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    image = Image.open(image_path)


    st.write('â‘¡startãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„')
    button = st.button('startï¼')

    if button:
     
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’æº–å‚™ã™ã‚‹
        audio_files = ['./sound/resnet34afrobeat.mp3','./sound/resnet34groovyRumba1mer.mp3','./sound/ResNet34romanticFolk.mp3', './sound/resnet34chillReggae.mp3','./sound/resnet34sanba1.mp3','./sound/resnet34sanba2.mp3','./sound/ResNet34Folk.mp3','./sound/ResNet34upliftingMetal.mp3']
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã™ã‚‹
        audio_path = random.choice(audio_files) 
        audio_placeholder = st.empty()

        file_ = open(audio_path, "rb")
        contents = file_.read()
        file_.close()

        audio_str = "data:audio/ogg;base64,%s" % (base64.b64encode(contents).decode())
        audio_html = """
                        <audio autoplay=True>
                        <source src="%s" type="audio/ogg" autoplay=True>
                        Your browser does not support the audio element.
                        </audio>
                    """ % audio_str

        audio_placeholder.empty()
        time.sleep(0.5) #ã“ã‚ŒãŒãªã„ã¨ä¸Šæ‰‹ãå†ç”Ÿã•ã‚Œã¾ã›ã‚“
        audio_placeholder.markdown(audio_html, unsafe_allow_html=True)



        # ç”»åƒã®å›è»¢æƒ…å ±ã‚’ç„¡è¦–ã—ã¦é–‹ã
        try:
            for orientation in ExifTags.TAGS.keys():
                if ExifTags.TAGS[orientation] == 'Orientation':
                    break
            exif = dict(image._getexif().items())

            if exif[orientation] == 3:
                image = image.rotate(180, expand=True)
            elif exif[orientation] == 6:
                image = image.rotate(270, expand=True)
            elif exif[orientation] == 8:
                image = image.rotate(90, expand=True)
        except (AttributeError, KeyError, IndexError):
            # ç”»åƒã«Exifæƒ…å ±ãŒãªã„å ´åˆã‚„ã€å›è»¢æƒ…å ±ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            pass
        
        #st.image(image, caption='Uploaded Image.', use_column_width=True)
        st.image(image, caption='Uploaded Image.', width=250)

        
        
        # ç”»åƒã®å‰å‡¦ç†
        def preprocess_image(image):
            transform = transforms.Compose([
                transforms.Resize((224, 224)),  # ãƒ¢ãƒ‡ãƒ«ã«åˆã‚ã›ã¦ç”»åƒã®ã‚µã‚¤ã‚ºã‚’èª¿æ•´
                transforms.ToTensor(),  # ç”»åƒã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
                #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ç”»åƒã‚’æ­£è¦åŒ–
            ])
            image = transform(image).unsqueeze(0)  # ãƒãƒƒãƒã®æ¬¡å…ƒã‚’è¿½åŠ 
            return image


          #äºˆæ¸¬ã¾ã§ã®ãƒãƒ¼ã‚’æŒ¿å…¥
        progress_text = "ğŸµãªã«ãŒã§ã‚‹ã‹ãªã€€ãªã«ãŒã§ã‚‹ã‹ãªã€€ãã‚Œã¯ResNet34ä»»ã›ã‚ˆï½"
        my_bar = st.progress(0, text=progress_text) 

        st.write('Â© Made With Suno')
        
        for percent_complete in range(100):
            time.sleep(0.13)
            my_bar.progress(percent_complete + 1, text=progress_text)
        time.sleep(1)
        my_bar.empty()

        st.button("Rerun")

        if image is not None:
            # ç”»åƒã®å‰å‡¦ç†
            image_tensor = preprocess_image(image)
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æº–å‚™
            net = Net().cpu().eval() 
            # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
            net.load_state_dict(torch.load('mnist-rn34-2.pt', map_location=torch.device('cpu')))

    

        # åˆ¤å®š
        with torch.no_grad():
            outputs = net(image_tensor)
            print(outputs)
            _, predicted = torch.max(outputs, 1)
          #  print(predicted.item())
            prediction = labels[predicted.item()]
            prediction_class = prediction 
        st.write(f"äºˆæ¸¬: {prediction}")
        # st.write(f"äºˆæ¸¬: {outputs}")
 
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
        image_name = os.path.basename(selected_image_file)

        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åã¨æ­£è§£å€¤ã®å¯¾å¿œè¡¨
        image_to_label = {
            "01.jpg": "ãµã¤ã†ã®å­ã€€ğŸ˜‘",
            "02.jpg": "Really?ã€€Soybeans?? ğŸ‘»ã€€ãªã‚“ã ã‚­ãƒŸã¯ï¼Ÿ",
            "03.jpg": "Really?ã€€Soybeans?? ğŸ‘»ã€€ãªã‚“ã ã‚­ãƒŸã¯ï¼Ÿ",
            "04.jpg": "ãµã¤ã†ã®å­ã€€ğŸ˜‘",
            "05.jpg": "ã„ã„å­ã€€ğŸ˜",
            "06.jpg": "ãµã¤ã†ã®å­ã€€ğŸ˜‘",
            "07.jpg": "Really?ã€€Soybeans?? ğŸ‘»ã€€ãªã‚“ã ã‚­ãƒŸã¯ï¼Ÿ",
            "10.jpg": "ãµã¤ã†ã®å­ã€€ğŸ˜‘",
            "08.jpg": "ã„ã„å­ã€€ğŸ˜",
            "09.jpg": "ã‚ã‚‹ã„å­ã€€ğŸ˜­",
            "11.jpg": "ã„ã„å­ã€€ğŸ˜",
            "12.jpg": "Really?ã€€Soybeans?? ğŸ‘»ã€€ãªã‚“ã ã‚­ãƒŸã¯ï¼Ÿ",
            "13.jpg": "ãµã¤ã†ã®å­ã€€ğŸ˜‘",
            "14.jpg": "ã‚ã‚‹ã„å­ã€€ğŸ˜­",
            "15.jpg": "Really?ã€€Soybeans?? ğŸ‘»ã€€ãªã‚“ã ã‚­ãƒŸã¯ï¼Ÿ",
            "16.jpg": "Really?ã€€Soybeans?? ğŸ‘»ã€€ãªã‚“ã ã‚­ãƒŸã¯ï¼Ÿ",
            "17.jpg": "ã‚ã‚‹ã„å­ã€€ğŸ˜­",
            "18.jpg": "ã„ã„å­ã€€ğŸ˜",
            "19.jpg": "ã‚ã‚‹ã„å­ã€€ğŸ˜­",
            "20.jpg": "Really?ã€€Soybeans?? ğŸ‘»ã€€ãªã‚“ã ã‚­ãƒŸã¯ï¼Ÿ",
            "21.jpg": "Really?ã€€Soybeans?? ğŸ‘»ã€€ãªã‚“ã ã‚­ãƒŸã¯ï¼Ÿ",
            "22.jpg": "ã‚ã‚‹ã„å­ã€€ğŸ˜­",
            "23.jpg": "Really?ã€€Soybeans?? ğŸ‘»ã€€ãªã‚“ã ã‚­ãƒŸã¯ï¼Ÿ",
             }

        #ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åã¨éŸ³æºã®å¯¾å¿œè¡¨
        image_to_audio = {
            "01.jpg": "./sound/normalChild.mp3",
            "02.jpg": "./sound/kurumi.mp3",
            "03.jpg": "./sound/ninniku.mp3",
            "04.jpg": "./sound/normalChild.mp3",
            "05.jpg": "./sound/goodChild.mp3",
            "06.jpg": "./sound/normalChild.mp3",
            "07.jpg": "./sound/uzuramame.mp3",
            "08.jpg": "./sound/goodChild.mp3",
            "09.jpg": "./sound/badChild.mp3",
            "10.jpg": "./sound/normalChild.mp3",
            "11.jpg": "./sound/goodChild.mp3",
            "12.jpg": "./sound/kuroninniku.mp3",
            "13.jpg": "./sound/normalChild.mp3",
            "14.jpg": "./sound/badChild.mp3",
            "15.jpg": "./sound/hanamame.mp3",
            "16.jpg": "./sound/kurogoma.mp3",
            "17.jpg": "./sound/badChild.mp3",
            "18.jpg": "./sound/goodChild.mp3",
            "19.jpg": "./sound/badChild.mp3",
            "20.jpg": "./sound/sirohanamame.mp3",
            "21.jpg": "./sound/kuroninniku.mp3",
            "22.jpg": "./sound/badChild.mp3",
            "23.jpg": "./sound/aobatamame.mp3",
            # ä»–ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åã¨ãã‚Œã«å¯¾å¿œã™ã‚‹éŸ³æºãƒ•ã‚¡ã‚¤ãƒ«åã‚‚è¿½åŠ ã—ã¾ã™
            }
        

        #ç”»åƒã«å¯¾å¿œã™ã‚‹æ­£è§£å€¤ã‚’å–å¾—
        if selected_image_file in image_to_label:
            label = image_to_label[image_name]
            st.write("æ­£è§£:", label)

         # Streamlitã‚¢ãƒ—ãƒªã®æ­£è§£å€¤
            true_value = label  # ã“ã“ã«æ­£è§£ã®å€¤ã‚’è¨­å®š

        if  prediction_class == true_value:
            st.write("**äºˆæ¸¬ãŒæ­£è§£ã¨ä¸€è‡´ã—ã¾ã—ãŸã€‚**")

            # ä¸€è‡´ã—ãŸå ´åˆã®éŸ³ã‚’å†ç”Ÿ
            sound_file_correct = "./sound/levelUP.mp3"  # ä¸€è‡´ã—ãŸå ´åˆã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¨­å®š
            pygame.mixer.music.load(sound_file_correct)
            pygame.mixer.music.play()

            # æ­£è§£éŸ³ãŒçµ‚ã‚ã‚‹ã¾ã§å¾…æ©Ÿ
            while pygame.mixer.music.get_busy():
                time.sleep(0.1)

            # æ­£è§£éŸ³ãŒçµ‚ã‚ã£ãŸå¾Œã«ç”»åƒã«å¯¾å¿œã™ã‚‹éŸ³å£°ã‚’å†ç”Ÿ
            if selected_image_file in image_to_audio:
                audio_path = image_to_audio[selected_image_file]
                pygame.mixer.music.load(audio_path)
                pygame.mixer.music.play()
                st.write('Â©ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼šéŸ³èª­ã•ã‚“')

            # éŸ³å£°å†ç”ŸãŒçµ‚äº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
            while pygame.mixer.music.get_busy():
                time.sleep(0.1)
        else:
            st.write("**äºˆæ¸¬ãŒæ­£è§£ã¨ä¸€è‡´ã—ã¾ã›ã‚“ã€‚**")

            # ç•°ãªã£ãŸå ´åˆã®éŸ³ã‚’å†ç”Ÿ
            sound_file_incorrect = "./sound/clumsy2.mp3"  # ç•°ãªã£ãŸå ´åˆã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¨­å®š
            pygame.mixer.music.load(sound_file_incorrect)
            pygame.mixer.music.play()

            # éŸ³å£°å†ç”ŸãŒçµ‚äº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
            while pygame.mixer.music.get_busy():
                time.sleep(0.1)

            # ç”»åƒã«å¯¾å¿œã™ã‚‹éŸ³å£°ã‚’å†ç”Ÿ
            if selected_image_file in image_to_audio:
                audio_path = image_to_audio[selected_image_file]
                pygame.mixer.music.load(audio_path)
                pygame.mixer.music.play()
                st.write('ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€€éŸ³èª­ã•ã‚“')

            # éŸ³å£°å†ç”ŸãŒçµ‚äº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
            while pygame.mixer.music.get_busy():
                time.sleep(0.1)
    
                
        #äºˆæ¸¬ç¢ºç‡ã‚’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤º   
        # äºˆæ¸¬ã•ã‚ŒãŸãƒ†ãƒ³ã‚½ãƒ«ã®å€¤ã‚’å–å¾—
        predicted_values = outputs.squeeze().tolist()

        # äºˆæ¸¬ã•ã‚ŒãŸãƒ†ãƒ³ã‚½ãƒ«ã®å€¤ã‚’Pandasã®DataFrameã«å¤‰æ›
        data = {'Class': list(labels.values()), 'Probability': predicted_values}
        df = pd.DataFrame(data)

        # ãƒã‚¤ãƒŠã‚¹ã¨ãƒ—ãƒ©ã‚¹ã®å ´åˆã§è‰²ã‚’å¤‰ãˆã‚‹é–¢æ•°ã‚’å®šç¾©
        def color_condition(probability):
            return 'red' if probability < 0 else 'blue'

        # Plotlyã‚’ä½¿ç”¨ã—ã¦æ£’ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã—ã€å¹…ã‚’èª¿æ•´
        fig = px.bar(df,x='Class', y='Probability', text='Probability')
        fig.update_traces(texttemplate='%{text:.4f}', textposition='outside') # ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æŒ‡å®š
        fig.update_layout(height=550, width=500, title='Predicted Probabilities(äºˆæ¸¬ç¢ºç‡)', yaxis=dict(title='äºˆæ¸¬ã—ãŸç¢ºç‡'))
        # ãƒãƒ¼ã®è‰²ã‚’è¨­å®š
        fig.update_traces(marker=dict(color=df['Probability'].apply(color_condition)))
        
        # Streamlitã§Plotlyã®ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º
        st.plotly_chart(fig)

    
if __name__ == "__main__":
    main()
